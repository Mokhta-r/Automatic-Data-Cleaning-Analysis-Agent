{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a379ba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# 04 - Analysis & Report Generation\n",
    "# Automatic Data Cleaning & Analysis Agent\n",
    "# ========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee05854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_descriptive_stats(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Compute descriptive statistics for numeric columns.\n",
    "    \"\"\"\n",
    "    numeric_df = df.select_dtypes(include=np.number)\n",
    "    if numeric_df.empty:\n",
    "        return {}\n",
    "    return numeric_df.describe().to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38131bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlations(df: pd.DataFrame, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Compute correlation matrix and extract strong correlations.\n",
    "    \"\"\"\n",
    "    numeric_df = df.select_dtypes(include=np.number)\n",
    "    if numeric_df.empty:\n",
    "        return {\"correlation_matrix\": {}, \"strong_correlations\": []}\n",
    "\n",
    "    corr = numeric_df.corr()\n",
    "\n",
    "    strong_pairs = []\n",
    "    for col1 in corr.columns:\n",
    "        for col2 in corr.columns:\n",
    "            if col1 < col2:\n",
    "                if abs(corr.loc[col1, col2]) >= threshold:\n",
    "                    strong_pairs.append({\n",
    "                        \"col1\": col1,\n",
    "                        \"col2\": col2,\n",
    "                        \"correlation\": float(corr.loc[col1, col2])\n",
    "                    })\n",
    "\n",
    "    return {\n",
    "        \"correlation_matrix\": corr.to_dict(),\n",
    "        \"strong_correlations\": strong_pairs\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd29b49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_distributions(df: pd.DataFrame):\n",
    "    numeric_df = df.select_dtypes(include=np.number)\n",
    "    summaries = {}\n",
    "\n",
    "    for col in numeric_df.columns:\n",
    "        series = numeric_df[col].dropna()\n",
    "        summaries[col] = {\n",
    "            \"min\": float(series.min()),\n",
    "            \"max\": float(series.max()),\n",
    "            \"mean\": float(series.mean()),\n",
    "            \"median\": float(series.median()),\n",
    "            \"skewness\": float(series.skew()),\n",
    "            \"q1\": float(series.quantile(0.25)),\n",
    "            \"q3\": float(series.quantile(0.75))\n",
    "        }\n",
    "\n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ab52c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_insights(descriptive, correlations, distributions, cleaning_report):\n",
    "    insights = []\n",
    "\n",
    "    # Strong correlations\n",
    "    for pair in correlations[\"strong_correlations\"]:\n",
    "        insights.append(\n",
    "            f\"Strong correlation ({pair['correlation']:.2f}) between **{pair['col1']}** and **{pair['col2']}**.\"\n",
    "        )\n",
    "\n",
    "    # Skewed distributions\n",
    "    for col, dist in distributions.items():\n",
    "        if abs(dist[\"skewness\"]) > 1:\n",
    "            insights.append(f\"Column **{col}** has a skewed distribution (skewness={dist['skewness']:.2f}).\")\n",
    "\n",
    "    # Many imputations\n",
    "    for col, info in cleaning_report[\"imputations\"].items():\n",
    "        if info[\"n_imputed\"] > 0:\n",
    "            insights.append(f\"Column **{col}** had {info['n_imputed']} missing values imputed.\")\n",
    "\n",
    "    # Outliers still present\n",
    "    for col, out in cleaning_report[\"outliers\"][\"details\"].items():\n",
    "        insights.append(f\"Column **{col}** contains {out['n_outliers']} outliers.\")\n",
    "\n",
    "    return insights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57cf3905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_warnings(cleaning_report):\n",
    "    warnings = []\n",
    "\n",
    "    # Dropped columns\n",
    "    if cleaning_report[\"dropped_columns\"]:\n",
    "        warnings.append(f\"Columns dropped due to high missing values: {', '.join(cleaning_report['dropped_columns'])}\")\n",
    "\n",
    "    # Too many imputations\n",
    "    for col, info in cleaning_report[\"imputations\"].items():\n",
    "        if info[\"n_imputed\"] > 5:\n",
    "            warnings.append(f\"High number of imputations for **{col}** ({info['n_imputed']}).\")\n",
    "\n",
    "    # Outliers not removed\n",
    "    if cleaning_report[\"outliers\"][\"n_rows_removed\"] == 0 and cleaning_report[\"outliers\"][\"details\"]:\n",
    "        warnings.append(\"Outliers detected but not removed.\")\n",
    "\n",
    "    return warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc51cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_markdown_report(\n",
    "    profile, cleaning_report, descriptive, correlations, distributions, insights, warnings\n",
    "):\n",
    "    md = []\n",
    "    md.append(\"# üìä Data Analysis Report\\n\")\n",
    "\n",
    "    md.append(\"## 1Ô∏è‚É£ Dataset Overview\")\n",
    "    md.append(f\"- Shape: **{profile['shape']}**\")\n",
    "    md.append(f\"- Columns: {', '.join(profile['columns'])}\\n\")\n",
    "\n",
    "    md.append(\"## 2Ô∏è‚É£ Cleaning Summary\")\n",
    "    md.append(f\"- Shape before: {cleaning_report['shape_before']}\")\n",
    "    md.append(f\"- Shape after: {cleaning_report['shape_after']}\")\n",
    "    md.append(f\"- Dropped columns: {cleaning_report['dropped_columns']}\")\n",
    "    md.append(f\"- Duplicates removed: {cleaning_report['duplicates']['n_removed']}\\n\")\n",
    "\n",
    "    md.append(\"### Imputations\")\n",
    "    for col, info in cleaning_report[\"imputations\"].items():\n",
    "        md.append(f\"- **{col}** ‚Üí {info['strategy']} (imputed {info['n_imputed']} values)\")\n",
    "\n",
    "    md.append(\"\\n## 3Ô∏è‚É£ Descriptive Statistics\")\n",
    "    if descriptive:\n",
    "        for col, stats in descriptive.items():\n",
    "            md.append(f\"### {col}\")\n",
    "            for s, val in stats.items():\n",
    "                md.append(f\"- {s}: {val}\")\n",
    "    else:\n",
    "        md.append(\"No numeric columns.\\n\")\n",
    "\n",
    "    md.append(\"\\n## 4Ô∏è‚É£ Correlations\")\n",
    "    if correlations[\"strong_correlations\"]:\n",
    "        md.append(\"### Strong correlations:\")\n",
    "        for pair in correlations[\"strong_correlations\"]:\n",
    "            md.append(\n",
    "                f\"- **{pair['col1']}** ‚Üî **{pair['col2']}** ‚Üí {pair['correlation']:.2f}\"\n",
    "            )\n",
    "    else:\n",
    "        md.append(\"No strong correlations found.\\n\")\n",
    "\n",
    "    md.append(\"\\n## 5Ô∏è‚É£ Distribution Summaries\")\n",
    "    for col, stats in distributions.items():\n",
    "        md.append(f\"### {col}\")\n",
    "        for s, val in stats.items():\n",
    "            md.append(f\"- {s}: {val}\")\n",
    "\n",
    "    md.append(\"\\n## 6Ô∏è‚É£ Insights\")\n",
    "    for i in insights:\n",
    "        md.append(f\"- {i}\")\n",
    "\n",
    "    md.append(\"\\n## 7Ô∏è‚É£ Warnings\")\n",
    "    if warnings:\n",
    "        for w in warnings:\n",
    "            md.append(f\"- ‚ö†Ô∏è {w}\")\n",
    "    else:\n",
    "        md.append(\"- No warnings detected.\")\n",
    "\n",
    "    return \"\\n\".join(md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "893b69ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_markdown_report(md_content: str, filename=\"../reports/analysis_report.md\"):\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(md_content)\n",
    "    print(f\"Report saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0476927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'data' ready.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent/src folder to python path\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "from cleaning_tools import clean_dataset, display_cleaning_report\n",
    "from data_tools import profile_dataset  # Importing profile_dataset from data_tools.py\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8405f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53f0a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8179e38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report saved to ../reports/analysis_report.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\Desktop\\projects\\Automatic-Data-Cleaning-Analysis-Agent\\src\\cleaning_tools.py:131: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_imputed[col].fillna(value, inplace=True)\n",
      "c:\\Users\\dell\\Desktop\\projects\\Automatic-Data-Cleaning-Analysis-Agent\\src\\cleaning_tools.py:131: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_imputed[col].fillna(value, inplace=True)\n",
      "c:\\Users\\dell\\Desktop\\projects\\Automatic-Data-Cleaning-Analysis-Agent\\src\\cleaning_tools.py:157: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_imputed[col].fillna(value, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# üìä Data Analysis Report\n",
       "\n",
       "## 1Ô∏è‚É£ Dataset Overview\n",
       "- Shape: **(20, 4)**\n",
       "- Columns: id, age, income, city\n",
       "\n",
       "## 2Ô∏è‚É£ Cleaning Summary\n",
       "- Shape before: (20, 4)\n",
       "- Shape after: (20, 4)\n",
       "- Dropped columns: []\n",
       "- Duplicates removed: 0\n",
       "\n",
       "### Imputations\n",
       "- **age** ‚Üí median (imputed 5 values)\n",
       "- **income** ‚Üí median (imputed 6 values)\n",
       "- **city** ‚Üí mode (imputed 6 values)\n",
       "\n",
       "## 3Ô∏è‚É£ Descriptive Statistics\n",
       "### id\n",
       "- count: 20.0\n",
       "- mean: 10.5\n",
       "- std: 5.916079783099616\n",
       "- min: 1.0\n",
       "- 25%: 5.75\n",
       "- 50%: 10.5\n",
       "- 75%: 15.25\n",
       "- max: 20.0\n",
       "### age\n",
       "- count: 20.0\n",
       "- mean: 34.05\n",
       "- std: 5.145002685283939\n",
       "- min: 25.0\n",
       "- 25%: 31.5\n",
       "- 50%: 34.0\n",
       "- 75%: 36.25\n",
       "- max: 44.0\n",
       "### income\n",
       "- count: 20.0\n",
       "- mean: 4005.0\n",
       "- std: 430.0856707802834\n",
       "- min: 3000.0\n",
       "- 25%: 3875.0\n",
       "- 50%: 4050.0\n",
       "- 75%: 4225.0\n",
       "- max: 4700.0\n",
       "\n",
       "## 4Ô∏è‚É£ Correlations\n",
       "### Strong correlations:\n",
       "- **id** ‚Üî **income** ‚Üí 0.82\n",
       "- **age** ‚Üî **id** ‚Üí 0.88\n",
       "- **age** ‚Üî **income** ‚Üí 0.87\n",
       "\n",
       "## 5Ô∏è‚É£ Distribution Summaries\n",
       "### id\n",
       "- min: 1.0\n",
       "- max: 20.0\n",
       "- mean: 10.5\n",
       "- median: 10.5\n",
       "- skewness: 0.0\n",
       "- q1: 5.75\n",
       "- q3: 15.25\n",
       "### age\n",
       "- min: 25.0\n",
       "- max: 44.0\n",
       "- mean: 34.05\n",
       "- median: 34.0\n",
       "- skewness: 0.10715522387337376\n",
       "- q1: 31.5\n",
       "- q3: 36.25\n",
       "### income\n",
       "- min: 3000.0\n",
       "- max: 4700.0\n",
       "- mean: 4005.0\n",
       "- median: 4050.0\n",
       "- skewness: -0.7188934095275396\n",
       "- q1: 3875.0\n",
       "- q3: 4225.0\n",
       "\n",
       "## 6Ô∏è‚É£ Insights\n",
       "- Strong correlation (0.82) between **id** and **income**.\n",
       "- Strong correlation (0.88) between **age** and **id**.\n",
       "- Strong correlation (0.87) between **age** and **income**.\n",
       "- Column **age** had 5 missing values imputed.\n",
       "- Column **income** had 6 missing values imputed.\n",
       "- Column **city** had 6 missing values imputed.\n",
       "- Column **age** contains 1 outliers.\n",
       "- Column **income** contains 2 outliers.\n",
       "\n",
       "## 7Ô∏è‚É£ Warnings\n",
       "- ‚ö†Ô∏è High number of imputations for **income** (6).\n",
       "- ‚ö†Ô∏è High number of imputations for **city** (6).\n",
       "- ‚ö†Ô∏è Outliers detected but not removed."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Load cleaned dataset + cleaning report (from previous notebook)\n",
    "path = \"../data/test_messy.csv\"\n",
    "df_raw = pd.read_csv(path)\n",
    "df_clean, cleaning_report = clean_dataset(df_raw)\n",
    "\n",
    "# Build profile\n",
    "profile = profile_dataset(df_raw)\n",
    "\n",
    "# Compute analysis\n",
    "descriptive = compute_descriptive_stats(df_clean)\n",
    "correlations = compute_correlations(df_clean)\n",
    "distributions = summarize_distributions(df_clean)\n",
    "\n",
    "# Generate insights & warnings\n",
    "insights = generate_insights(descriptive, correlations, distributions, cleaning_report)\n",
    "warnings = generate_warnings(cleaning_report)\n",
    "\n",
    "# Build Markdown report\n",
    "md = build_markdown_report(\n",
    "    profile, cleaning_report, descriptive, correlations, distributions, insights, warnings\n",
    ")\n",
    "\n",
    "# Save report\n",
    "save_markdown_report(md)\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06798a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_cleaned.to_csv(\"df_clean.csv\", index=False)\n",
    "print(\"‚úî Cleaned dataset saved as df_clean.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
