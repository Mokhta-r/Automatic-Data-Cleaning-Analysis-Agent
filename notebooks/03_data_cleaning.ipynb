{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb05fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# 03 - Data Cleaning\n",
    "# Automatic Data Cleaning & Analysis Agent\n",
    "# ========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ddeef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CLEANING_CONFIG = {\n",
    "    \"missing_threshold_drop_column\": 0.6,   # si > 60% NaN -> drop colonne\n",
    "    \"impute_numeric\": \"median\",            # \"mean\" ou \"median\"\n",
    "    \"impute_categorical\": \"mode\",          # \"mode\" ou \"constant\"\n",
    "    \"impute_categorical_constant\": \"Unknown\",\n",
    "    \"remove_duplicates\": True,\n",
    "    \"outlier_method\": \"iqr\",               # pour l'instant: \"iqr\" seulement\n",
    "    \"outlier_iqr_multiplier\": 1.5,\n",
    "    \"remove_outliers\": False               # False = seulement les signaler\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4f472d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_config(user_config: dict | None, default: dict = DEFAULT_CLEANING_CONFIG) -> dict:\n",
    "    \"\"\"Merge user provided config with default config.\"\"\"\n",
    "    if user_config is None:\n",
    "        return default.copy()\n",
    "    merged = default.copy()\n",
    "    merged.update(user_config)\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8488bef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_high_missing_columns(df: pd.DataFrame, threshold: float):\n",
    "    \"\"\"\n",
    "    Drop columns with fraction of missing values > threshold.\n",
    "    Returns: df_reduced, dropped_columns (list)\n",
    "    \"\"\"\n",
    "    missing_fraction = df.isna().mean()\n",
    "    cols_to_drop = missing_fraction[missing_fraction > threshold].index.tolist()\n",
    "    df_reduced = df.drop(columns=cols_to_drop) if cols_to_drop else df.copy()\n",
    "    return df_reduced, cols_to_drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "416384d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(df: pd.DataFrame, config: dict):\n",
    "    \"\"\"\n",
    "    Impute missing values according to config.\n",
    "    Returns: df_imputed, imputation_report (dict)\n",
    "    \"\"\"\n",
    "    df_imputed = df.copy()\n",
    "    imputation_report = {}\n",
    "\n",
    "    numeric_cols = df_imputed.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_cols = df_imputed.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "    # Numeric imputation\n",
    "    for col in numeric_cols:\n",
    "        n_missing = df_imputed[col].isna().sum()\n",
    "        if n_missing == 0:\n",
    "            continue\n",
    "\n",
    "        strategy = config[\"impute_numeric\"]\n",
    "        if strategy == \"median\":\n",
    "            value = df_imputed[col].median()\n",
    "        elif strategy == \"mean\":\n",
    "            value = df_imputed[col].mean()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown numeric imputation strategy: {strategy}\")\n",
    "\n",
    "        df_imputed[col].fillna(value, inplace=True)\n",
    "        imputation_report[col] = {\n",
    "            \"type\": \"numeric\",\n",
    "            \"strategy\": strategy,\n",
    "            \"value_used\": float(value),\n",
    "            \"n_imputed\": int(n_missing),\n",
    "        }\n",
    "\n",
    "    # Categorical imputation\n",
    "    for col in categorical_cols:\n",
    "        n_missing = df_imputed[col].isna().sum()\n",
    "        if n_missing == 0:\n",
    "            continue\n",
    "\n",
    "        strategy = config[\"impute_categorical\"]\n",
    "        if strategy == \"mode\":\n",
    "            if df_imputed[col].dropna().empty:\n",
    "                value = config[\"impute_categorical_constant\"]\n",
    "            else:\n",
    "                value = df_imputed[col].mode(dropna=True)[0]\n",
    "        elif strategy == \"constant\":\n",
    "            value = config[\"impute_categorical_constant\"]\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown categorical imputation strategy: {strategy}\")\n",
    "\n",
    "        df_imputed[col].fillna(value, inplace=True)\n",
    "        imputation_report[col] = {\n",
    "            \"type\": \"categorical\",\n",
    "            \"strategy\": strategy,\n",
    "            \"value_used\": str(value),\n",
    "            \"n_imputed\": int(n_missing),\n",
    "        }\n",
    "\n",
    "    return df_imputed, imputation_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f707992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(df: pd.DataFrame, config: dict):\n",
    "    \"\"\"\n",
    "    Impute missing values according to config.\n",
    "    Returns: df_imputed, imputation_report (dict)\n",
    "    \"\"\"\n",
    "    df_imputed = df.copy()\n",
    "    imputation_report = {}\n",
    "\n",
    "    numeric_cols = df_imputed.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_cols = df_imputed.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "    # Numeric imputation\n",
    "    for col in numeric_cols:\n",
    "        n_missing = df_imputed[col].isna().sum()\n",
    "        if n_missing == 0:\n",
    "            continue\n",
    "\n",
    "        strategy = config[\"impute_numeric\"]\n",
    "        if strategy == \"median\":\n",
    "            value = df_imputed[col].median()\n",
    "        elif strategy == \"mean\":\n",
    "            value = df_imputed[col].mean()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown numeric imputation strategy: {strategy}\")\n",
    "\n",
    "        df_imputed[col].fillna(value, inplace=True)\n",
    "        imputation_report[col] = {\n",
    "            \"type\": \"numeric\",\n",
    "            \"strategy\": strategy,\n",
    "            \"value_used\": float(value),\n",
    "            \"n_imputed\": int(n_missing),\n",
    "        }\n",
    "\n",
    "    # Categorical imputation\n",
    "    for col in categorical_cols:\n",
    "        n_missing = df_imputed[col].isna().sum()\n",
    "        if n_missing == 0:\n",
    "            continue\n",
    "\n",
    "        strategy = config[\"impute_categorical\"]\n",
    "        if strategy == \"mode\":\n",
    "            if df_imputed[col].dropna().empty:\n",
    "                value = config[\"impute_categorical_constant\"]\n",
    "            else:\n",
    "                value = df_imputed[col].mode(dropna=True)[0]\n",
    "        elif strategy == \"constant\":\n",
    "            value = config[\"impute_categorical_constant\"]\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown categorical imputation strategy: {strategy}\")\n",
    "\n",
    "        df_imputed[col].fillna(value, inplace=True)\n",
    "        imputation_report[col] = {\n",
    "            \"type\": \"categorical\",\n",
    "            \"strategy\": strategy,\n",
    "            \"value_used\": str(value),\n",
    "            \"n_imputed\": int(n_missing),\n",
    "        }\n",
    "\n",
    "    return df_imputed, imputation_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa087725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_duplicates(df: pd.DataFrame, remove: bool = True):\n",
    "    \"\"\"\n",
    "    Detect (and optionally remove) duplicate rows.\n",
    "    Returns: df_dedup, n_duplicates\n",
    "    \"\"\"\n",
    "    duplicated_mask = df.duplicated()\n",
    "    n_duplicates = int(duplicated_mask.sum())\n",
    "\n",
    "    if remove and n_duplicates > 0:\n",
    "        df_dedup = df[~duplicated_mask].copy()\n",
    "    else:\n",
    "        df_dedup = df.copy()\n",
    "\n",
    "    return df_dedup, n_duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad419109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(df: pd.DataFrame, multiplier: float = 1.5):\n",
    "    \"\"\"\n",
    "    Detect outliers per numeric column using IQR rule.\n",
    "    Returns:\n",
    "        outlier_indices_per_column: dict[col -> list of indices]\n",
    "    \"\"\"\n",
    "    outlier_indices = {}\n",
    "    numeric_df = df.select_dtypes(include=np.number)\n",
    "\n",
    "    for col in numeric_df.columns:\n",
    "        series = numeric_df[col].dropna()\n",
    "        if series.empty:\n",
    "            continue\n",
    "\n",
    "        q1 = series.quantile(0.25)\n",
    "        q3 = series.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - multiplier * iqr\n",
    "        upper = q3 + multiplier * iqr\n",
    "\n",
    "        mask = (numeric_df[col] < lower) | (numeric_df[col] > upper)\n",
    "        idx = numeric_df[mask].index.tolist()\n",
    "\n",
    "        if idx:\n",
    "            outlier_indices[col] = {\n",
    "                \"lower_bound\": float(lower),\n",
    "                \"upper_bound\": float(upper),\n",
    "                \"indices\": idx,\n",
    "                \"n_outliers\": len(idx),\n",
    "            }\n",
    "\n",
    "    return outlier_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce5c61ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df: pd.DataFrame, user_config: dict | None = None):\n",
    "    \"\"\"\n",
    "    Full cleaning pipeline:\n",
    "    - Drop columns with too many missing values\n",
    "    - Impute remaining missing values\n",
    "    - Remove duplicate rows\n",
    "    - Detect (and optionally remove) outliers\n",
    "    Returns: df_clean, cleaning_report (dict)\n",
    "    \"\"\"\n",
    "    config = merge_config(user_config, DEFAULT_CLEANING_CONFIG)\n",
    "    report = {\n",
    "        \"dropped_columns\": [],\n",
    "        \"imputations\": {},\n",
    "        \"duplicates\": {\n",
    "            \"n_duplicates_before\": 0,\n",
    "            \"n_removed\": 0\n",
    "        },\n",
    "        \"outliers\": {\n",
    "            \"method\": config[\"outlier_method\"],\n",
    "            \"details\": {},\n",
    "            \"n_rows_removed\": 0\n",
    "        },\n",
    "        \"shape_before\": df.shape,\n",
    "        \"shape_after\": None\n",
    "    }\n",
    "\n",
    "    # 1) Drop high-missing columns\n",
    "    df_step, cols_dropped = drop_high_missing_columns(\n",
    "        df,\n",
    "        threshold=config[\"missing_threshold_drop_column\"]\n",
    "    )\n",
    "    report[\"dropped_columns\"] = cols_dropped\n",
    "\n",
    "    # 2) Impute missing values\n",
    "    df_step, imputation_report = impute_missing_values(df_step, config)\n",
    "    report[\"imputations\"] = imputation_report\n",
    "\n",
    "    # 3) Handle duplicates\n",
    "    n_duplicates_before = int(df_step.duplicated().sum())\n",
    "    df_step, n_removed_dup = handle_duplicates(\n",
    "        df_step,\n",
    "        remove=config[\"remove_duplicates\"]\n",
    "    )\n",
    "    report[\"duplicates\"][\"n_duplicates_before\"] = n_duplicates_before\n",
    "    report[\"duplicates\"][\"n_removed\"] = n_removed_dup\n",
    "\n",
    "    # 4) Detect outliers\n",
    "    outlier_details = {}\n",
    "    if config[\"outlier_method\"] == \"iqr\":\n",
    "        outlier_details = detect_outliers_iqr(\n",
    "            df_step,\n",
    "            multiplier=config[\"outlier_iqr_multiplier\"]\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown outlier method: {config['outlier_method']}\")\n",
    "\n",
    "    report[\"outliers\"][\"details\"] = outlier_details\n",
    "\n",
    "    # Optionally remove outliers\n",
    "    if config[\"remove_outliers\"] and outlier_details:\n",
    "        # build a mask of all outlier indices\n",
    "        all_indices = set()\n",
    "        for col, info in outlier_details.items():\n",
    "            all_indices.update(info[\"indices\"])\n",
    "        n_rows_outliers = len(all_indices)\n",
    "        report[\"outliers\"][\"n_rows_removed\"] = n_rows_outliers\n",
    "\n",
    "        df_step = df_step.drop(index=list(all_indices))\n",
    "\n",
    "    # Final shape\n",
    "    report[\"shape_after\"] = df_step.shape\n",
    "\n",
    "    return df_step, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c7f347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def display_cleaning_report(report: dict):\n",
    "    print(\"=== Cleaning Report ===\")\n",
    "    print(f\"Shape before: {report['shape_before']}\")\n",
    "    print(f\"Shape after : {report['shape_after']}\")\n",
    "    print(\"\\nDropped columns:\", report[\"dropped_columns\"])\n",
    "\n",
    "    print(\"\\nImputations:\")\n",
    "    if report[\"imputations\"]:\n",
    "        for col, info in report[\"imputations\"].items():\n",
    "            print(f\"  - {col}: {info}\")\n",
    "    else:\n",
    "        print(\"  None\")\n",
    "\n",
    "    print(\"\\nDuplicates:\")\n",
    "    print(f\"  Duplicates before: {report['duplicates']['n_duplicates_before']}\")\n",
    "    print(f\"  Duplicates removed: {report['duplicates']['n_removed']}\")\n",
    "\n",
    "    print(\"\\nOutliers:\")\n",
    "    print(f\"  Method: {report['outliers']['method']}\")\n",
    "    print(f\"  Rows removed (if configured): {report['outliers']['n_rows_removed']}\")\n",
    "    print(\"  Details per column:\")\n",
    "    if report[\"outliers\"][\"details\"]:\n",
    "        for col, info in report[\"outliers\"][\"details\"].items():\n",
    "            print(f\"    - {col}: {info['n_outliers']} outliers\")\n",
    "    else:\n",
    "        print(\"    None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85e682ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_8624\\3859962653.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_imputed[col].fillna(value, inplace=True)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_8624\\3859962653.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_imputed[col].fillna(value, inplace=True)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_8624\\3859962653.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_imputed[col].fillna(value, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cleaning Report ===\n",
      "Shape before: (20, 4)\n",
      "Shape after : (20, 4)\n",
      "\n",
      "Dropped columns: []\n",
      "\n",
      "Imputations:\n",
      "  - age: {'type': 'numeric', 'strategy': 'median', 'value_used': 34.0, 'n_imputed': 5}\n",
      "  - income: {'type': 'numeric', 'strategy': 'median', 'value_used': 4050.0, 'n_imputed': 6}\n",
      "  - city: {'type': 'categorical', 'strategy': 'mode', 'value_used': 'Paris', 'n_imputed': 6}\n",
      "\n",
      "Duplicates:\n",
      "  Duplicates before: 0\n",
      "  Duplicates removed: 0\n",
      "\n",
      "Outliers:\n",
      "  Method: iqr\n",
      "  Rows removed (if configured): 0\n",
      "  Details per column:\n",
      "    - age: 1 outliers\n",
      "    - income: 2 outliers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>Lyon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4050.0</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>Marseille</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age  income       city\n",
       "0   1  25.0  3000.0      Paris\n",
       "1   2  26.0  3200.0       Lyon\n",
       "2   3  27.0  4050.0      Paris\n",
       "3   4  34.0  4000.0      Paris\n",
       "4   5  29.0  3500.0  Marseille"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test cleaning on messy dataset\n",
    "path_messy = \"../data/test_messy.csv\"\n",
    "df_messy = pd.read_csv(path_messy)\n",
    "\n",
    "df_messy_clean, messy_report = clean_dataset(df_messy)\n",
    "\n",
    "display_cleaning_report(messy_report)\n",
    "df_messy_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee202b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cleaning Report ===\n",
      "Shape before: (22, 3)\n",
      "Shape after : (19, 3)\n",
      "\n",
      "Dropped columns: []\n",
      "\n",
      "Imputations:\n",
      "  None\n",
      "\n",
      "Duplicates:\n",
      "  Duplicates before: 0\n",
      "  Duplicates removed: 0\n",
      "\n",
      "Outliers:\n",
      "  Method: iqr\n",
      "  Rows removed (if configured): 3\n",
      "  Details per column:\n",
      "    - temperature: 3 outliers\n",
      "    - humidity: 2 outliers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>21.779629</td>\n",
       "      <td>49.387901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>23.639454</td>\n",
       "      <td>52.927804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23.618778</td>\n",
       "      <td>42.930079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21.434908</td>\n",
       "      <td>64.801538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>23.133212</td>\n",
       "      <td>62.891970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  temperature   humidity\n",
       "0   1    21.779629  49.387901\n",
       "1   2    23.639454  52.927804\n",
       "2   3    23.618778  42.930079\n",
       "3   4    21.434908  64.801538\n",
       "4   5    23.133212  62.891970"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_outliers = \"../data/test_outliers_duplicates.csv\"\n",
    "df_outliers = pd.read_csv(path_outliers)\n",
    "\n",
    "# Exemple: ici on d√©cide de supprimer les outliers\n",
    "config_remove_outliers = {\n",
    "    \"remove_outliers\": True\n",
    "}\n",
    "\n",
    "df_outliers_clean, outliers_report = clean_dataset(df_outliers, config_remove_outliers)\n",
    "\n",
    "display_cleaning_report(outliers_report)\n",
    "df_outliers_clean.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
